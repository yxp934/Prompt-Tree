# 产品需求文档：基于拓扑节点的上下文可视化 AI 客户端

## 1. 核心愿景
目前的 AI 聊天工具将上下文（Context）视为不可控的黑盒，导致用户在进行深度思考或多任务处理时，无法精准控制模型的输入边界。

本产品的目标是**“上下文的可视化与工程化”**。通过将对话片段抽象为可操作、可压缩、可组装的“节点”，让用户像操作 Git 树一样管理对话历史，像组装乐高积木一样定义当前的“上下文箱子”，从而实现对 AI 思考过程的完全掌控。

## 2. 核心数据模型设计

系统不存储线性的消息列表，而是存储一张**有向无环图（DAG）**。所有的交互均围绕“节点”展开。

### 2.1 节点 结构
节点是系统最小的原子单位。每一个节点在数据库中是一个独立的对象，包含以下核心属性：

*   **基础身份 (ID & Type)**：唯一标识符，区分节点类型（普通对话节点、压缩节点、系统指令节点）。
*   **血缘关系**：指向其唯一的“父节点”。这意味着每一个节点的诞生都源于某个具体的父状态。
*   **内容载荷**：
    *   原始文本（用户输入或 AI 输出）。
    *   结构化摘要（针对压缩节点）。
*   **元数据记忆**：这是一个关键扩展字段。当节点被压缩时，系统会提取该路径上隐含的“元指令”，例如 `lang:zh-CN` (语言), `format:markdown` (格式), `role:expert` (角色)。
*   **资源属性**：该节点本身包含的 Token 数量估算值。

### 2.2 上下文箱子
这是用户发给 AI 的“最终包裹”。它不是自动计算的，而是用户通过 UI 操作“组装”出来的逻辑集合。它在 UI 上表现为一个“显性的底座”。

## 3. 前端交互与视觉设计

### 3.1 主视图：对话树图
放弃传统的滚动聊天列表，采用“树状画布”作为主视图。

*   **布局逻辑**：
    *   横轴（X轴）代表时间或对话轮次。
    *   纵轴（Y轴）代表分支。
    *   每一个“输入/输出”对在图上显示为一个节点。节点连线清晰展示了思维的演变路径。
*   **智能摘要显示**：
    *   为了防止树图过于臃肿，节点在 UI 上默认只显示“核心摘要”，而非全文。只有鼠标悬停或点击时，才展开全文。
    *   摘要由用户在压缩时生成，或者由客户端本地提取关键句生成。
*   **路径染色**：
    *   当用户选中树上的某个末端节点时，系统会自动高亮从“根节点”到该节点的完整路径。
    *   **颜色标记**：如果该路径上存在一个“压缩节点”，则该压缩节点之后的整条路径（包括子节点）都会被赋予特定的主题色（例如淡蓝色背景），以此提示用户：“后续的对话是基于此前被压缩的上下文进行的”。

### 3.2 核心交互 1：手动压缩
用户拥有绝对的主动权来决定何时压缩历史。

*   **操作流**：用户在树上框选一段连续的节点 -> 点击右键“压缩为上下文”。
*   **生成物**：系统将这些节点合并，生成一个新的 **“压缩节点”**。原节点被折叠隐藏，视觉上变为一个带标签的方块（如“项目背景调研 v1”）。
*   **元指令提取**：在压缩生成的瞬间，客户端自动扫描被选中的文本，提取出显著的元指令，并将其标注在压缩节点的属性上。

### 3.3 核心交互 2：上下文插拔
这是本产品最革命性的功能。用户不再被动地接受“上下文窗口”，而是主动构建它。

*   **UI 布局**：在树状图的下方或右侧，设置一个固定的 **“上下文组装台”**。
*   **操作逻辑**：
    *   用户可以从树状图的任意位置，拖拽一个节点（无论是原始对话节点，还是压缩后的总结节点）放入“组装台”。
    *   用户也可以将树上的某个分支路径直接“钉”到组装台。
*   **视觉反馈**：
    *   组装台内的卡片列表即为“当前发送给 AI 的所有上下文”。
    *   **Token 占用进度条**：在组装台的顶部，显眼地展示一个进度条。每增加一个节点，进度条增长，并显示百分比（如“当前占用：1248 Tokens / 85%”）。
    *   这迫使开发者意识到上下文的经济成本，并学会通过“压缩”来腾挪空间。

### 3.4 特殊指令节点
除了对话产生的压缩节点，系统允许用户创建纯指令节点。

*   **定义**：这是一种特殊的叶子节点，通常只包含设定规则（如“你是一个 Rust 专家”、“所有回复必须是 JSON”）。
*   **用途**：它可以被拖拽进“组装台”作为临时的系统提示词插入，也可以作为“记忆锚点”挂载在树的某个分叉上，改变后续分支的行为风格。
*   **可视化**：在树图中以醒目的颜色（如紫色）区分。

### 3.5 交互流程示例
1.  用户开始一个新的编程任务，输入需求（节点 A）。AI 回复（节点 B）。
2.  用户进行多轮调试，形成节点 C、D、E。
3.  用户发现 Token 占用过高，且背景设定已经固定。他框选了 A 到 E，点击“压缩”。
4.  A-E 消失，变为一个蓝色的压缩节点 `Summary(A-E)`。
5.  用户基于这个总结继续提问，生成新的子节点 F。
6.  此时，用户想要在另一个分支测试不同的方案。他点击节点 B，分叉出新路径 G。
7.  在路径 G 上，用户想复用之前压缩过的经验。他直接将 `Summary(A-E)` 这个节点拖拽到下方的“上下文组装台”中。
8.  此时，节点 G 的输入不仅包含它自己的历史，还强行包含了 A-E 的上下文。

## 4. 关键功能边界设定

*   **无自动总结**：为了性能和准确性，系统默认不自动调用 LLM 进行总结。压缩动作仅在用户显式触发时执行，或由用户在本地通过简单的规则（如提取首句）进行预览。
*   **状态隔离**：树上的不同分支默认拥有独立的上下文环境。只有通过“跨分支拖拽”才能打破隔离。

## 5. 总结
这个设计方案将 AI 聊天从“流式记事本”进化为“思维栈管理器”。通过可视化的树状图保留思维的拓扑结构，通过显性的压缩节点和组装台实现对上下文窗口的精细化管理。这不仅解决了开发者对于“模型到底读了什么”的焦虑，更提供了一种符合人类非线性直觉的思考辅助工具。
